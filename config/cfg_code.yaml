# Code Generation Training Config

defaults:
  - arch: code_optimized
  - _self_

hydra:
  output_subdir: null

# Data path
data_paths: ['data/code-python']
data_paths_test: []

evaluators: []

# Training hyperparams (optimized for code)
global_batch_size: 16  # Smaller for longer sequences
epochs: 50
eval_interval: 5
checkpoint_every_eval: True

# Learning rates
lr: 2e-4  # Slightly lower for code
lr_min_ratio: 0.1
lr_warmup_steps: 1000

# Optimizer
beta1: 0.9
beta2: 0.95
weight_decay: 0.01

# No puzzle embeddings
puzzle_emb_lr: 0.0
puzzle_emb_weight_decay: 0.0

seed: 42
min_eval_interval: 0

checkpoint_path: "checkpoints/code-trm-13m"

ema: False
ema_rate: 0.999
freeze_weights: False

# TRM Recursive Reasoning Features (NEW)
enable_dqn: true
enable_entropy_regularization: true
entropy_regularization_weight: 0.01
enable_memory: true
enable_mtp: true
enable_adaptive_hcycles: true
hcycle_confidence_threshold: 2.0
enable_hierarchical_attention: true
q_head_num_actions: 3
q_head_type: "mlp"
