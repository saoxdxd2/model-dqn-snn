# Multimodal HESC Architecture
# Optimized for 12-capsule hierarchical semantic encoding
# Use case: Text + Vision + Structured data with capsule compression

name: recursive_reasoning.trm@TinyRecursiveReasoningModel_ACTV1
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy

# ===== HESC-Optimized Recursion =====
# Derived for seq_len=12 (capsules), not 900 (pixels)
# Total recursions: 3 Ã— (2+1) = 9 forward passes
H_cycles: 3  # High-level reasoning iterations
L_cycles: 2  # Low-level processing per H-cycle

halt_exploration_prob: 0.1
halt_max_steps: 16

# ===== Model Architecture =====
H_layers: 0
L_layers: 2  # 2-layer transformer (TRM paper optimal)

hidden_size: 512  # Capsule embedding dimension
num_heads: 8      # Attention heads
num_key_value_heads: 2  # GQA: 4:1 ratio (58% memory reduction)
expansion: 4      # FFN expansion

puzzle_emb_ndim: ${.hidden_size}
puzzle_emb_len: 16

pos_encodings: rope
forward_dtype: float16
rope_theta: 10000

mlp_t: False
no_ACT_continue: True

# ===== Deep Supervision (Aligned with recursion depth) =====
# With 9 total recursions, supervise every 1.5 steps
deep_supervision_steps: 6  # Supervision checkpoints
enable_gradient_checkpointing: True  # 68% memory reduction

# ===== Stability (Critical for HESC) =====
use_ema: True
ema_decay: 0.999

# ===== DQN (DISABLED - Paper validates simple ACT > DQN) =====
enable_dqn: False
dqn_buffer_capacity: 500000  # Corrected from 20K (was filling in <1 step)
dqn_buffer_min_size: 50000
dqn_batch_size: 256
dqn_gamma: 0.99
dqn_epsilon_start: 0.3
dqn_epsilon_end: 0.05
dqn_epsilon_decay_steps: 100000
dqn_warmstart_steps: 10000  # Oracle heuristic warm-start

# ===== Reward Shaping =====
reward_step_penalty: 0.01
reward_terminal_correct: 1.0
reward_terminal_incorrect: -0.5

# ===== Q-Head =====
q_head_type: mlp
q_head_hidden_size: 128
q_head_num_layers: 1

# ===== Memory Bank (DISABLED) =====
enable_memory: False
memory_capacity: 4096
memory_num_heads: 8
memory_dropout: 0.1
memory_reward_bonus: 0.5
memory_reward_threshold: 0.05

# ===== Intrinsic Curiosity (DISABLED) =====
enable_count_curiosity: False
enable_rnd_curiosity: False
curiosity_count_beta: 0.05
curiosity_rnd_weight: 0.1

# ===== Entropy Regularization (DISABLED) =====
enable_entropy_regularization: False
entropy_regularization_weight: 0.01

# ===== Prioritized Replay (DISABLED unless DQN enabled) =====
enable_prioritized_replay: False
per_alpha: 0.6
per_beta: 0.4

# ===== Multi-Token Prediction (DISABLED) =====
enable_mtp: False
mtp_num_depths: 3
mtp_loss_weight: 0.5
mtp_share_embeddings: True
mtp_share_output_head: True

# ===== HESC-Specific Parameters =====
# Reconstruction loss weight (from our fixes)
reconstruction_weight: 0.5
checksum_halt_threshold: 0.5

# ===== Optimization =====
cpu_optimized: False
use_gelu: True
ffn_expansion_ratio: 4.0
