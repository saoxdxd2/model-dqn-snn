name: recursive_reasoning.transformers_baseline@Model_ACTV2
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy
  enable_dqn: False  # Baseline doesn't use DQN

halt_exploration_prob: 0.1
halt_max_steps: 16
act_enabled: True  # Enable ACT halting during training
act_inference: False  # Fixed steps during inference for fair comparison

H_cycles: 16  # Single level, so cycles = max steps

H_layers: 6  # Standard transformer depth

hidden_size: 512
num_heads: 8
expansion: 4

puzzle_emb_ndim: ${.hidden_size}

pos_encodings: rope
forward_dtype: float16
