# TRM Unified Architecture
# Same TRM used for vision encoding AND reasoning!

name: recursive_reasoning.trm@TinyRecursiveReasoningModel_ACTV1
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy

# ===== TRM Encoder (Vision) =====
use_trm_encoder: true
trm_encoder_layers: 2
trm_encoder_H_cycles: 2
trm_encoder_L_cycles: 3
# Total: 2×3 = 6 passes for encoding

# ===== TRM Reasoner (Downstream) =====
H_cycles: 3  # High-level reasoning
L_cycles: 6  # Low-level processing
# Total: 3×6 = 18 passes for reasoning

halt_exploration_prob: 0.1
halt_max_steps: 64

# Unified: Same block architecture!
H_layers: 0
L_layers: 2  # Same 2 layers used in both encoder and reasoner

# ===== Model Architecture =====
hidden_size: 512
num_heads: 8
num_key_value_heads: 2  # GQA
expansion: 4

puzzle_emb_ndim: 0  # No puzzle embeddings in vision-unified mode
puzzle_emb_len: 0
num_puzzle_identifiers: 0

pos_encodings: rope
forward_dtype: float16
rope_theta: 10000

mlp_t: False
no_ACT_continue: True
causal: false  # Non-causal for vision

# ===== Deep Supervision =====
deep_supervision_steps: 6
enable_gradient_checkpointing: True

# ===== Stability =====
use_ema: True
ema_decay: 0.999

# ===== DQN =====
enable_dqn: True
dqn_buffer_capacity: 500000
dqn_buffer_min_size: 1000
dqn_batch_size: 128
dqn_gamma: 0.99
dqn_epsilon_start: 0.3
dqn_epsilon_end: 0.05
dqn_epsilon_decay_steps: 200000
dqn_warmstart_steps: 10000

# ===== Reward Shaping =====
reward_step_penalty: 0.01
reward_terminal_correct: 1.0
reward_terminal_incorrect: -0.5

# ===== Q-Head =====
q_head_type: mlp
q_head_hidden_size: 128
q_head_num_layers: 1

# ===== Memory Bank =====
enable_memory: True
memory_capacity: 4096
memory_num_heads: 8
memory_dropout: 0.1

# ===== Intrinsic Curiosity =====
enable_count_curiosity: True
enable_rnd_curiosity: True

# ===== Multi-Token Prediction =====
enable_mtp: True
mtp_num_depths: 3
mtp_loss_weight: 0.5

# ===== HESC-Specific =====
reconstruction_weight: 0.5
checksum_halt_threshold: 0.5

# ===== TRM Features =====
enable_adaptive_hcycles: true
hcycle_confidence_threshold: 2.0
enable_hierarchical_attention: true
enable_capsule_expansion: false
q_head_num_actions: 3

# ===== Optimization =====
cpu_optimized: False
use_gelu: True
ffn_expansion_ratio: 4.0

# ===== Vision Encoder Config =====
use_semantic_encoder: true
encoder_model: trm  # Use TRM instead of CLIP
target_capsules: 12
children_per_capsule: 4
checksum_dim: 32
freeze_capsule_encoder: false  # Train encoder on ARC!

# Output vocabulary
num_concepts: 2048
use_vq_codebook: true
vocab_size: 2052  # 2048 concepts + 4 control
