{
  "tokenizer_name": "gpt2",
  "vocab_size": 50257,
  "pad_token_id": 0,
  "eos_token_id": 50256,
  "max_seq_len": 512
}